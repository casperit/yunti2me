<?xml version="1.0" encoding="UTF-8"?>

<configuration>
  <property>
    <name>dfs.client.failover.proxy.provider.DClusterNmg</name>
    <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
  </property>
  <property>
    <name>dfs.ha.automatic-failover.enabled</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.ha.fencing.ssh.private-key-files</name>
    <value>/home/hadoop/.ssh/id_rsa</value>
  </property>
  <property>
    <name>dfs.ha.namenodes.DClusterNmg</name>
    <value>nn1,nn2</value>
  </property>
  <property>
    <name>dfs.heartbeat.expire.interval</name>
    <value>1200000</value>
  </property>
  <property>
    <name>dfs.hosts</name>
    <value>/home/hadoop/hadoop-current/etc/hadoop/slaves</value>
  </property>
  <property>
    <name>dfs.hosts.exclude</name>
    <value>/home/hadoop/hadoop-current/etc/hadoop/exclude</value>
  </property>
  <property>
    <name>dfs.image.transfer.bandwidthPerSec</name>
    <value>629145600</value>
  </property>
  <property>
    <name>dfs.image.transfer.timeout</name>
    <value>600000</value>
  </property>
  <property>
    <name>dfs.namenode.audit.log.async</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.namenode.checkpoint.period</name>
    <value>3600</value>
  </property>
  <property>
    <name>dfs.namenode.checkpoint.txns</name>
    <value>1000000000</value>
  </property>
  <property>
    <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
    <value>false</value>
  </property>
  <property>
    <name>dfs.namenode.handler.count</name>
    <value>64</value>
  </property>
  <property>
    <name>dfs.namenode.http-address.DClusterNmg.nn1</name>
    <value>bigdata-nmg-hdpnn00.nmg01:50070</value>
  </property>
  <property>
    <name>dfs.namenode.http-address.DClusterNmg.nn2</name>
    <value>bigdata-nmg-hdpnn01.nmg01:50070</value>
  </property>
  <property>
    <name>dfs.namenode.invalidate.work.pct.per.iteration</name>
    <value>0.25f</value>
  </property>
  <property>
    <name>dfs.namenode.name.dir</name>
    <value>file:///data/hadoopdata/hadoop-namenode</value>
  </property>
  <property>
    <name>dfs.namenode.num.checkpoints.retained</name>
    <value>5</value>
  </property>
  <property>
    <name>dfs.namenode.replication.interval</name>
    <value>10</value>
  </property>
  <property>
    <name>dfs.namenode.replication.max-streams</name>
    <value>500</value>
  </property>
  <property>
    <name>dfs.namenode.replication.max-streams-hard-limit</name>
    <value>1000</value>
  </property>
  <property>
    <name>dfs.namenode.replication.work.multiplier.per.iteration</name>
    <value>8</value>
  </property>
  <property>
    <name>dfs.namenode.rpc-address.DClusterNmg.nn1</name>
    <value>bigdata-nmg-hdpnn00.nmg01:8020</value>
  </property>
  <property>
    <name>dfs.namenode.rpc-address.DClusterNmg.nn2</name>
    <value>bigdata-nmg-hdpnn01.nmg01:8020</value>
  </property>
  <property>
    <name>dfs.namenode.service.handler.count</name>
    <value>50</value>
  </property>
  <property>
    <name>dfs.namenode.servicerpc-address.DClusterNmg.nn1</name>
    <value>bigdata-nmg-hdpnn00.nmg01:8021</value>
  </property>
  <property>
    <name>dfs.namenode.servicerpc-address.DClusterNmg.nn2</name>
    <value>bigdata-nmg-hdpnn01.nmg01:8021</value>
  </property>
  <property>
    <name>dfs.namenode.shared.edits.dir</name>
    <value>qjournal://bigdata-nmg-hdpnn00.nmg01:8485;bigdata-nmg-hdpnn01.nmg01:8485;bigdata-nmg-hdpnn02.nmg01:8485/DClusterNmg</value>
  </property>
  <property>
    <name>dfs.nameservices</name>
    <value>DClusterNmg</value>
  </property>
  <property>
    <name>dfs.qjournal.select-input-streams.timeout.ms</name>
    <value>120000</value>
  </property>
  <property>
    <name>dfs.qjournal.start-segment.timeout.ms</name>
    <value>120000</value>
  </property>
  <property>
    <name>dfs.qjournal.write-txns.timeout.ms</name>
    <value>120000</value>
  </property>
  <property>
    <name>fs.protected.directories</name>
    <value>/user/xiaoju/data/bi</value>
  </property>
  <property>
    <name>rpc.metrics.percentiles.intervals</name>
    <value>10</value>
  </property>
  <property>
    <name>rpc.metrics.quantile.enable</name>
    <value>false</value>
  </property>
  <property>
    <name>dfs.namenode.quota.init-threads</name>
    <value>8</value>
  </property>
  <property>
    <name>dfs.namenode.balancer.request.standby</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.webhdfs.enabled</name>
    <value>false</value>
  </property>
  <property>
    <name>dfs.namenode.support.allow.format</name>
    <value>false</value>
    <description>Does HDFS namenode allow itself to be formatted?
               You may consider setting this to false for any production
               cluster, to avoid any possibility of formatting a running DFS.
    </description>
  </property>
  <property>
    <name>hadoop.caller.context.enabled</name>
    <value>true</value>
  </property>
  <property>
    <name>fs.protected.directories.use.file.enable</name>
    <value>true</value>
  </property>
  <property>
    <name>fs.protected.directories.file</name>
    <value>/home/hadoop/hadoop-current/etc/hadoop/protecteddirectories.txt</value>
  </property>
  <property>
    <name>dfs.namenode.edits.asynclogging</name>
    <value>true</value>
  </property>
</configuration>
